{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# teradataml preparing the features and training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the teradataml package for Vantage access\n",
    "from teradataml import *\n",
    "import getpass\n",
    "from teradataml import display\n",
    "#display.print_sqlmr_query=True\n",
    "from sqlalchemy.sql.expression import select, case as case_when, func\n",
    "from sqlalchemy import TypeDecorator, Integer, String\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vantage = 'tdap1627t2.labs.teradata.com'\n",
    "User = 'alice'\n",
    "Pass = 'alice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vantage = '10.25.251.121'\n",
    "User = 'USER10'\n",
    "Pass = 'USER10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass = getpass.getpass(prompt=\"pwd: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.25.251.121 USER10\n"
     ]
    }
   ],
   "source": [
    "print(Vantage,User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = create_context(Vantage, User, Pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the explain text feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Set Selection\n",
    "dbqlog = DataFrame.from_table(in_schema(\"dbc\", \"dbqlogtbl\")).drop(\"ZoneId\", axis = 1)\n",
    "dbqlexplain = DataFrame.from_table(in_schema(\"dbc\", \"dbqlexplaintbl\")).drop(\"ZoneID\", axis = 1)\n",
    "dbqldata = dbqlog.join(other = dbqlexplain, on = [\"QueryID\"], lsuffix = \"t1\", rsuffix = \"t2\") \\\n",
    "    .select(['t1_QueryID','ExplainText','QueryBand','QueryText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround until ELE-2072.\n",
    "dbqldata.to_sql('prediction_sentiment', if_exists=\"replace\")\n",
    "dbqldata = DataFrame.from_table('prediction_sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup training and join condition features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "df_select_query_column_projection = [\n",
    "     dbqldata.t1_QueryID.expression.label(\"queryid\"),\n",
    "     dbqldata.ExplainText.expression.label(\"explaintext\"),\n",
    "     dbqldata.QueryBand.expression.label(\"queryband\"),\n",
    "     func.REGEXP_SUBSTR(dbqldata.QueryBand.expression, \n",
    "                        '(collected_statistics|no_statistics)', 1, 1, 'i').label(\"training\"),\n",
    "     func.REGEXP_SUBSTR(dbqldata.QueryText.expression, \n",
    "                        'SELECT', 1, 1, 'i').label(\"select_info\"),\n",
    "     func.REGEXP_SUBSTR(func.REGEXP_SUBSTR(dbqldata.ExplainText.expression, \n",
    "                        '(joined using a *[A-z \\-]+ join,)', 1, 1, 'i'), \n",
    "                            '[A-z]+', 15, 1, 'i').label(\"join_condition\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = DataFrame.from_query(str(select(df_select_query_column_projection)\n",
    "                                 .where(Column('join_condition') != None)\n",
    "                                 .where(Column('training') != None)\n",
    "                                 .compile(compile_kwargs={\"literal_binds\": True})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to provide the training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish training data\n",
    "training_data = DataFrame.from_query(str(select(df_select_query_column_projection)\n",
    "                                 .compile(compile_kwargs={\"literal_binds\": True})))\n",
    "data_filter = (training_data.join_condition != None) & (training_data.training != None)  \\\n",
    "        & (training_data.select_info != None)\n",
    "data_set = training_data[data_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data set into training and testing sets\n",
    "training_set = Sampling(data = data_set, sample_fraction = 0.5, seed = 2).result\n",
    "testing_set = data_set.join(other = training_data, on = [\"queryid<>queryid\"], \n",
    "                            lsuffix = \"t1\", rsuffix = \"t2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   count_queryid  count_explaintext  count_queryband  count_training  count_select_info  count_join_condition\n",
       "0              0                  0                0               0                  0                     0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[training_set.training == 'collected_statistics'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing = tsample.result.join(other = training_data, on = [\"queryid<>queryid\"], lsuffix = \"t1\", rsuffix = \"t2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set = tsample.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom sentiment dictionary\n",
    "dictionary = DataFrame.from_table('dbql_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Confidience \n",
    "Features = SentimentExtractor(\n",
    "    #dict_data = dictionary,\n",
    "    newdata = training_set,\n",
    "    level = \"document\",\n",
    "    text_column = \"explaintext\",\n",
    "    accumulate = ['queryid','join_condition','training']\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(SentimentExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   count_queryid  count_join_condition  count_training  count_out_polarity  count_out_strength  count_out_sentiment_words\n",
       "0              0                     0               0                   0                   0                          0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the features for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = td_sentiment_extractor_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "stats_model = NaiveBayes(\n",
    "    formula=\"training ~ out_polarity + join_condition\", \n",
    "    data=Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "############ STDOUT Output ############\n",
       "\n",
       "Empty DataFrame\n",
       "Columns: [class_nb, variable_nb, type_nb, category, cnt, sum_nb, sum_sq, total_cnt]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'td_save_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a370e97540b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtd_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Stats_collection_model_final\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'td_save_model' is not defined"
     ]
    }
   ],
   "source": [
    "td_save_model(model = stats_model, name = \"Stats_collection_model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_model.result.to_sql(\"stats_model_final\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_collection = NaiveBayesPredict(newdata=Features,\n",
    "                                       modeldata = stats_model,\n",
    "                                       formula=\"training ~ out_polarity + join_condition\", \n",
    "                                       id_col = \"queryid\",\n",
    "                                       responses = [\"collected_statistics\",\"no_statistics\"]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = target_collection.result.join(other = Features, on = [\"queryid\"], lsuffix = \"t1\", \n",
    "                                        rsuffix = \"t2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                measure c_null collected_statistics no_statistics\n",
       "0        Detection Rate      0               0.0952        0.5238\n",
       "1           Sensitivity      0                    1             1\n",
       "2        Pos Pred Value     NA               0.6667        0.6111\n",
       "3            Prevalence  0.381               0.0952        0.5238\n",
       "4  Detection Prevalence      0               0.1429        0.8571\n",
       "5     Balanced Accuracy    0.5               0.9737          0.65\n",
       "6        Neg Pred Value  0.619                    1             1\n",
       "7           Specificity      1               0.9474           0.3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix(data = summary, prediction = 'prediction', reference = 'training').accuracytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                measure  c_null product   merge dynamic collected_statistics  nested no_statistics\n",
       "0        Detection Rate       0       0       0       0                    0       0             0\n",
       "1           Sensitivity       0       0       0       0                   NA       0            NA\n",
       "2        Pos Pred Value      NA      NA      NA      NA                   NA      NA            NA\n",
       "3            Prevalence  0.2857  0.0476  0.1905  0.1905                    0  0.2857             0\n",
       "4  Detection Prevalence       0       0       0       0               0.0476       0        0.9524\n",
       "5     Balanced Accuracy     0.5     0.5     0.5     0.5                   NA     0.5            NA\n",
       "6        Neg Pred Value  0.7143  0.9524  0.8095  0.8095                   NA  0.7143            NA\n",
       "7           Specificity       1       1       1       1               0.9524       1        0.0476"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix(data = summary, prediction = 'prediction', reference = 'join_condition').accuracytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-1cdd55343517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracytable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy.accuracytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NaiveBayes in module teradataml.analytics.mle.NaiveBayes:\n",
      "\n",
      "class NaiveBayes(builtins.object)\n",
      " |  NaiveBayes(formula=None, data=None, data_sequence_column=None, data_order_column=None)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, formula=None, data=None, data_sequence_column=None, data_order_column=None)\n",
      " |      DESCRIPTION:\n",
      " |          The NaiveBayesMap and NaiveBayesReduce functions generate a model from\n",
      " |          training data. A virtual data frame of training data is input to\n",
      " |          the NaiveBayesMap function, whose output is the input to\n",
      " |          NaiveBayesReduce function, which outputs the model.\n",
      " |      \n",
      " |      \n",
      " |      PARAMETERS:\n",
      " |          formula:\n",
      " |              Required Argument.\n",
      " |              A string consisting of \"formula\". Specifies the model to be fitted. Only\n",
      " |              basic formula of the \"col1 ~ col2 + col3 +...\" form is supported and\n",
      " |              all variables must be from the same virtual data frame object. The\n",
      " |              response should be column of type real, numeric, integer or boolean.\n",
      " |              Types: str\n",
      " |      \n",
      " |          data:\n",
      " |              Required Argument.\n",
      " |              This is teradataml DataFrame defining the input training data.\n",
      " |      \n",
      " |          data_order_column:\n",
      " |              Optional Argument.\n",
      " |              Specifies Order By columns for data.\n",
      " |              Values to this argument can be provided as a list, if multiple\n",
      " |              columns are used for ordering.\n",
      " |              Types: str OR list of Strings (str)\n",
      " |      \n",
      " |          data_sequence_column:\n",
      " |              Optional Argument.\n",
      " |              Specifies the list of column(s) that uniquely identifies each row of\n",
      " |              the input argument \"data\". The argument is used to ensure\n",
      " |              deterministic results for functions which produce results that vary\n",
      " |              from run to run.\n",
      " |              Types: str OR list of Strings (str)\n",
      " |      \n",
      " |      RETURNS:\n",
      " |          Instance of NaiveBayes.\n",
      " |          Output teradataml DataFrames can be accessed using attribute\n",
      " |          references, such as NaiveBayesObj.<attribute_name>.\n",
      " |          Output teradataml DataFrame attribute name is:\n",
      " |              result\n",
      " |      \n",
      " |      \n",
      " |      RAISES:\n",
      " |          TeradataMlException\n",
      " |      \n",
      " |      \n",
      " |      EXAMPLES:\n",
      " |          # Load the data to run the example\n",
      " |          load_example_data(\"NaiveBayes\",\"nb_iris_input_train\")\n",
      " |      \n",
      " |          # Create teradataml DataFrame object.\n",
      " |          nb_iris_input_train = DataFrame.from_table(\"nb_iris_input_train\")\n",
      " |      \n",
      " |          # Run the train function\n",
      " |          naivebayes_train = NaiveBayes(formula=\"species ~ petal_length + sepal_width + petal_width + sepal_length\",\n",
      " |                                        data=nb_iris_input_train)\n",
      " |      \n",
      " |          # Print the result DataFrame\n",
      " |          naivebayes_train.result\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Returns the string representation for a NaiveBayes class instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(NaiveBayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
