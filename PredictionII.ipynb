{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict when statistics need to be collected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the teradataml package for Vantage access\n",
    "from teradataml import *\n",
    "import getpass\n",
    "from teradataml import display\n",
    "#display.print_sqlmr_query=True\n",
    "from sqlalchemy.sql.expression import select, case as case_when, func\n",
    "from sqlalchemy import TypeDecorator, Integer, String\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vantage = 'tdap1627t2.labs.teradata.com'\n",
    "User = 'alice'\n",
    "Pass = 'alice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tdap1627t2.labs.teradata.com alice\n"
     ]
    }
   ],
   "source": [
    "print(Vantage,User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = create_context(Vantage, User, Pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Sentiment from the explains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbqlog = DataFrame.from_table(in_schema(\"dbc\", \"dbqlogtbl\")).drop(\"ZoneId\", axis = 1)\n",
    "dbqlexplain = DataFrame.from_table(in_schema(\"dbc\", \"dbqlexplaintbl\")).drop(\"ZoneID\", axis = 1)\n",
    "dbqldata = dbqlog.join(other = dbqlexplain, on = [\"QueryID\"], lsuffix = \"t1\", rsuffix = \"t2\") \\\n",
    "    .select(['t1_QueryID','ExplainText','QueryBand','QueryText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               t1_QueryID                                        ExplainText QueryBand                                          QueryText\n",
       "0  307190295502502401.000    1) First, we do an INSERT step into R_GLM_WO...      None  insert into R_GLM_WORKFLOWS_DB.r_music values ...\n",
       "1  307180295502824652.000    1) First, we lock ALICE.cars_hist in TD_MAP1...      None  CREATE MULTISET TABLE \"ALICE\".r__t__sqlmr_stdo...\n",
       "2  307170295502603825.000    1) First, we do an INSERT step into ALICE.ci...      None            insert into citvertices_2 values(2064);\n",
       "3  307160295502627742.000    1) First, we do an INSERT step into ALICE.co...      None  insert into computers_train1 values(1842,2995,...\n",
       "4  307170295502609392.000    1) First, we do an INSERT step into ALICE.su...      None  insert into surveys values(4583,6,5,1981,11,'O...\n",
       "5  307180295502804933.000    1) First, we do an INSERT step into ALICE.su...      None  insert into surveys values(18984,8,8,1991,6,'P...\n",
       "6  307170295502629111.000    1) First, we do an INSERT step into ALICE.su...      None  insert into surveys values(24290,8,14,1996,12,...\n",
       "7  307190295502496834.000    1) First, we do an INSERT step into R_GLM_WO...      None  insert into R_GLM_WORKFLOWS_DB.r_music values ...\n",
       "8  307160295502647461.000    1) First, we do an INSERT step into R_GLM_WO...      None  insert into R_GLM_WORKFLOWS_DB.r_music values ...\n",
       "9  307180295502779647.000    1) First, we do an INSERT step into R_GLM_WO...      None  insert into R_GLM_WORKFLOWS_DB.r_music values ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbqldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround until ELE-2072.\n",
    "dbqldata.to_sql('prediction_sentiment', if_exists=\"replace\")\n",
    "dbqldata = DataFrame.from_table('prediction_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select_query_column_projection = [\n",
    "     dbqldata.t1_QueryID.expression.label(\"queryid\"),\n",
    "     dbqldata.ExplainText.expression.label(\"explaintext\"),\n",
    "     dbqldata.QueryBand.expression.label(\"queryband\"),\n",
    "     func.REGEXP_SUBSTR(dbqldata.QueryBand.expression, \n",
    "                        '(collected_statistics|no_statistics)', 1, 1, 'i').label(\"training\"),\n",
    "     func.REGEXP_SUBSTR(dbqldata.QueryText.expression, \n",
    "                        'SELECT', 1, 1, 'i').label(\"select_info\"),\n",
    "     func.REGEXP_SUBSTR(func.REGEXP_SUBSTR(dbqldata.ExplainText.expression, \n",
    "                        '(joined using a *[A-z \\-]+ join,)', 1, 1, 'i'), \n",
    "                            '[A-z]+', 15, 1, 'i').label(\"join_condition\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = DataFrame.from_query(str(select(df_select_query_column_projection)\n",
    "                                 #.where(Column('join_condition') != None)\n",
    "                                 #.where(Column('training') != None)\n",
    "                                 .compile(compile_kwargs={\"literal_binds\": True})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = (prediction_data.join_condition != None)  & (prediction_data.training != None)\n",
    "prediction_set = prediction_data[data_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  queryid                                        explaintext                                  queryband              training select_info join_condition\n",
       "0  307170295502596206.000    1) First, we lock DBC.udt1 in view ColumnsV ...         =S> run=#jdf_8_00_2_no_statistics;         no_statistics      SELECT          merge\n",
       "1  307160295502622239.000    1) First, we lock DBC.DBase in view All_RI_C...         =S> run=#jdf_8_00_3_no_statistics;         no_statistics      SELECT        product\n",
       "2  307170295502596173.000    1) First, we lock DBC.DBase in view All_RI_C...         =S> run=#jdf_8_00_1_no_statistics;         no_statistics      SELECT        product\n",
       "3  307160295502622236.000    1) First, we lock DBC.udt1 in view ColumnsV ...         =S> run=#jdf_8_00_3_no_statistics;         no_statistics      SELECT          merge\n",
       "4  307160295502622374.000    1) First, we lock alice.d2 in TD_MAP1 for re...  =S> run=#jdf_8_84_7_collected_statistics;  collected_statistics      select        dynamic\n",
       "5  307170295502596169.000    1) First, we lock DBC.dbase in view tablesV ...         =S> run=#jdf_8_00_1_no_statistics;         no_statistics      SELECT          merge\n",
       "6  307170295502596205.000    1) First, we lock DBC.dbase in view tablesV ...         =S> run=#jdf_8_00_2_no_statistics;         no_statistics      SELECT          merge\n",
       "7  307170295502596172.000    1) First, we lock DBC.dbase in view Indices ...         =S> run=#jdf_8_00_1_no_statistics;         no_statistics      SELECT         nested\n",
       "8  307160295502622264.000    1) First, we lock alice.d2 in TD_MAP1 for re...  =S> run=#jdf_8_84_4_collected_statistics;  collected_statistics      select        dynamic\n",
       "9  307160295502622241.000    1) First, we lock DBC.dbase in view Indices ...         =S> run=#jdf_8_00_3_no_statistics;         no_statistics      SELECT         nested"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_data.select(['queryid', 'join_condition', 'explaintext', 'training'])\n",
    "# Workaround until ELE-2072.\n",
    "#prediction_set.to_sql('prediction_sentiment')\n",
    "#prediction_set = DataFrame.from_table('prediction_sentiment')\n",
    "prediction_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = DataFrame.from_table('dbql_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_sentiment_extractor_out = SentimentExtractor(\n",
    "    dict_data = dictionary,\n",
    "    newdata = prediction_set,\n",
    "    level = \"document\",\n",
    "    text_column = \"explaintext\",\n",
    "    accumulate = ['queryid','join_condition','training']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = td_sentiment_extractor_out.result #.to_sql('holdit4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              queryid join_condition              training out_polarity  out_strength                                out_sentiment_words\n",
       "0  307160295502622374        dynamic  collected_statistics          POS             2  high confidence 10, low confidence -5, high co...\n",
       "1  307170295502596205          merge         no_statistics          NEG             2  low confidence -5, no confidence -10, no confi...\n",
       "2  307170295502596172         nested         no_statistics          NEG             2  low confidence -5, no confidence -10, no confi...\n",
       "3  307170295502596170          merge         no_statistics          NEG             2  low confidence -5, no confidence -10, no confi...\n",
       "4  307170295502596209        product         no_statistics          NEG             2  no confidence -10, no confidence -10, no confi...\n",
       "5  307160295502622301        dynamic  collected_statistics          POS             2  high confidence 10, low confidence -5, high co...\n",
       "6  307160295502622235          merge         no_statistics          NEG             2  low confidence -5, no confidence -10, no confi...\n",
       "7  307170295502596169          merge         no_statistics          NEG             2  low confidence -5, no confidence -10, no confi...\n",
       "8  307160295502622264        dynamic  collected_statistics          POS             2  high confidence 10, low confidence -5, high co...\n",
       "9  307160295502622236          merge         no_statistics          NEG             2  low confidence -5, no confidence -10, no confi..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    con.execute(\"drop table target_collection\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_model = DataFrame.from_table(in_schema(\"alice\", \"stats_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why does it need formula?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict from queries columns needing collected statistics\n",
    "target_collection = NaiveBayesPredict(newdata=predict,\n",
    "                                       modeldata = stats_model,\n",
    "                                       formula=\"training ~ out_polarity + join_condition\", \n",
    "                                       id_col = \"queryid\",\n",
    "                                       responses = [\"collected_statistics\",\"no_statistics\"]\n",
    "                                       ).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_collection.result.to_sql('acc1', if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              queryid     prediction  loglik_no_statistics\n",
       "0  307160295502622374  no_statistics             -3.283414\n",
       "1  307170295502596205  no_statistics             -0.916291\n",
       "2  307170295502596172  no_statistics             -1.203973\n",
       "3  307170295502596170  no_statistics             -0.916291\n",
       "4  307170295502596209  no_statistics             -2.302585\n",
       "5  307160295502622301  no_statistics             -3.283414\n",
       "6  307160295502622235  no_statistics             -0.916291\n",
       "7  307170295502596169  no_statistics             -0.916291\n",
       "8  307160295502622264  no_statistics             -3.283414\n",
       "9  307160295502622236  no_statistics             -0.916291"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_collection.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  queryid\n",
       "0  307190295502491943.000\n",
       "1  307190295502491944.000\n",
       "2  307190295502491944.000\n",
       "3  307190295502491944.000\n",
       "4  307190295502491952.000\n",
       "5  307190295502491952.000\n",
       "6  307190295502491944.000\n",
       "7  307190295502491943.000\n",
       "8  307190295502491943.000\n",
       "9  307190295502491943.000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbqlobj = DataFrame.from_table('dbc.dbqlobjtbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain query's join information\n",
    "target_names = target_collection.result.join(other = dbqlobj, on = [\"queryid\"], lsuffix = \"t1\", \n",
    "        rsuffix = \"t2\").select('objectdatabasename', 'objecttablename', 'objectcolumnname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect statistics on each column\n",
    "for index, row in target_collection.result.to_pandas().iterrows():\n",
    "    con.execute('collect statistics column '+row['ObjectTableName']+\" on \"+ \\\n",
    "        row['ObjectDatabaseName']+'.'+row['ObjectTableName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how to test if table is still there, no help table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['collect statistics column DATA2 on alice.DATA2',\n",
       " 'collect statistics column DATA1 on alice.DATA1']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
